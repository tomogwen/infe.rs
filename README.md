# Infe.rs

To be rusty dockerised inference of ML models.

## Installation

- `pre-commit install`

## To Do

- Task queuer (add task to 'tasks' db, update with doing/done).
- Model inference.

### Building and running your application

When you're ready, start your application by running:
`docker compose up --build`.

Your application will be available at http://localhost:8000.
